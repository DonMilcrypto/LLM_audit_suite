MODEL_PATH=gpt2

# --- Hardware Optimization ---
# Adjust batch size based on VRAM availability.
# 8 is safe for most 12GB+ cards with small models.
BATCH_SIZE=8

# --- Generation Parameters ---
# Controls the randomness and length of the output
MAX_NEW_TOKENS=100
TEMPERATURE=0.8
TOP_K=50
TOP_P=0.95

# --- Audit Scope ---
# How many times to re-run the same prompt to check for consistency/determinism
ITERATIONS=3
